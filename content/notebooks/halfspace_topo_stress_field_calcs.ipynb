{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background of the topographic stress field calculations\n",
    "\n",
    "The weight of mountains (or other high topography) induces stresses in the\n",
    "earth below the topography. Unlike many other types of stress in the crust,\n",
    "topographic stresses are expected to have very significant spatial variation.\n",
    "Therefore, in regions with high topography, it is important to include\n",
    "topographic stresses into the overall stress budgets of the regions.\n",
    "\n",
    "But because of this spatial variation in topographic stresses, calculating them\n",
    "is not as straightforward as for some other stress components (such as\n",
    "lithostatic stress, which is basically $\\rho g z$). As explained in the\n",
    "[introduction][intro], we use some techniques based on treating the earth as an\n",
    "elastic halfspace to calculate the stresses. Elastic halfspaces do a good job\n",
    "of representing appropriate (time-invariant) stresses and strains in the earth\n",
    "due to forcing of various sorts. They also typically have simple and\n",
    "well-defined solutions for how the stresses and strains from simple,\n",
    "well-defined perturbations (i.e. other stresses and strains) propagate\n",
    "throughout the halfspace. \n",
    "\n",
    "When we calculate stresses with `halfspace`, we use a set of these solutions\n",
    "relating how a point load (force) of some known magnitude on the surface of the\n",
    "halfspace induces stresses throughout the halfspace. First, we approximate\n",
    "topography as a regularly-spaced array of vertical point loads \n",
    "([the Digital Elevation Model we prepared a couple steps back][dem_prep]), \n",
    "and use [Boussinesq][bouss]'s solutions for the stresses in the halfspace\n",
    "resulting from the vertical point loads. \n",
    "\n",
    "\n",
    "### First step: Vertical topographic forces\n",
    "Boussinesq's solutions are [Green's functions][gf] describing how the\n",
    "stresses radiate throughout a halfspace from a single, vertical point load on\n",
    "the surface (called $F_v$, which is equal to $-\\rho g z$).  The equations\n",
    "describe separate results for each of the six components of the stress tensor\n",
    "at any point in the halfspace. We will call the stresses from the vertical\n",
    "point sources $G^B_{ij}$, where $ij$ is the stress component of interest.\n",
    "\n",
    "$$ G_{xx}^B = \\frac{ F_v }{ 2\\pi } \\left[ \\frac{ 3x^2 z }{ r^5 } \\right. + \\frac{\\mu (y^2 + z^2)}{(\\lambda + \\mu) r^3 (z + r)}\n",
    "- \\frac{\\mu z}{(\\lambda + \\mu) r^3} \\left. - \\frac{\\mu x^2}{ (\\lambda + \\mu) r^2 (z + r)^2 }\\right ] $$\n",
    "\n",
    "$$ G_{yy}^B = \\frac{F_v}{2\\pi } \\left [ \\frac{3y^2 z}{r^5} \\right.\n",
    "+ \\frac{\\mu (x^{2} + z^{2})}{(\\lambda + \\mu) r^{3}(z + r)}\n",
    "- \\frac{\\mu z}{(\\lambda + \\mu) r ^{3}} \\left. - \\frac{\\mu y^{2}}{(\\lambda + \\mu ) r^2 (z +r)^2} \\right] $$\n",
    "\n",
    "$$ G_{xy}^{B} = \\frac{F _{v}}{2\\pi} \\left[ \\frac{3xyz}{r^{5}} - \\frac{\\mu x y (z + 2r)}{(\\lambda + \\mu) r^{3} (z + r)^{2}} \\right] $$\n",
    "\n",
    "$$ G_{zz}^{B} = 3 F _{v} z^{3} / 2 \\pi r^{5} $$\n",
    "\n",
    "$$ G_{xz}^{B} = 3 F _{v} xz^{2} / 2 \\pi r^{5} $$\n",
    "\n",
    "$$ G_{yz}^{B} = 3 F _{v} yz^{2} / 2 \\pi r^{5} $$\n",
    "\n",
    "\n",
    "![topo point load][point_load_image]\n",
    "*Stress components produced by a single point load*\n",
    "\n",
    "Next, we need to go from a single point load to an array of point loads. One of\n",
    "the nice things about small stresses and strains in elastic halfspaces is that\n",
    "they are addative, so the stress field from topography is basically the sum of\n",
    "the stresses from the individual point loads. We could go through point by\n",
    "point and calculate the stress field, but there is a much better way to do it.\n",
    "Because of the [superposition principle][sp], we can take the sort of general\n",
    "solution to the Boussinesq's solution above, i.e. when $F_v=1$, and\n",
    "[convolve][convolve] this with the field of vertical forces $F_v(x,y)$, which\n",
    "is the DEM times density $\\rho$ and gravitational force $g$, yielding the\n",
    "stress tensor field $M^B(x,y,z)$ (M stands for Mountain):\n",
    "\n",
    "$$ M^B(x,y,z) = G^B(x,y,z) * F_v(x,y)$$\n",
    "\n",
    "where $*$ is the convolution operator.\n",
    "\n",
    "![topo array load][array_load_image]\n",
    "*Stress componentes from an array of point loads representing topography*\n",
    "\n",
    "This calculation can be sped up tremendously (for large arrays) because of the\n",
    "[convolution theorem][conv_theor] which states that in cases like this, a \n",
    "convolution in the space domain is equivalent to a multiplication in the time\n",
    "domain. This means that we can take the Fourier transforms of both the Green's\n",
    "functions ($G^B$) calculated over some area, and the $F_v$ array, and then\n",
    "multiply those and transform the product back, instead of doing a space-domain\n",
    "convolution. This is great because both the Fourier transforms and the\n",
    "multiplication are much faster operations than the space-domain convolution.\n",
    "\n",
    "### Next step: Horizontal topographic forces\n",
    "\n",
    "Up to this point, the methods as described have been thought up by many\n",
    "scientists back to at least [Harold Jeffreys][hj]. However, the result isn't\n",
    "quite complete. [Liu and Zoback (1992)][lz92] took these calculations a step\n",
    "further and accounted for the effects of the irregular surface above (but\n",
    "connected to) the halfspace into account. This includes both a correction for\n",
    "the horizontal shear stress induced by the effects of slope on the halfspace,\n",
    "and for how the irregular surface affects the propagation of stresses.\n",
    "\n",
    "This step takes the topography and the uppermost stresses from the previous\n",
    "result, and yields a field of horizontal loads $F_h(x,y)$ at the surface\n",
    "of the halfspace. Then, it uses Cerruti's solutions for stresses in a halfspace\n",
    "from a *horizontal* point load on the surface to propagate those stresses. The\n",
    "steps are exactly the same as previously, except that the process has to be done\n",
    "for horizontal loads in both the $x$ and $y$ directions. This produces a stress\n",
    "field $M^C(x,y,z)$ that will be added to $M^B(x,y,z)$ to produce the final\n",
    "topographic stress field $M(x,y,z)$.\n",
    "\n",
    "The horizontal loading functions are\n",
    "\n",
    "$$ F_{h, \\, x}(x,y) = ( \\rho g h(x,y) + M_{xx}^B(x,y,0) + T^0_{xx} )\\, \\frac{\\partial h}{ \\partial x} + (M_{xy}^{B}(x,y,0) + T^0_{xy}) \\frac{\\partial h}{ \\partial y} $$\n",
    "\n",
    "and \n",
    "\n",
    "$$ F_{h, \\, yz}(x,y) = ( \\rho g h(x,y) + \\sigma_{yy}^B(x,y,0) + T^0_{yy} )\\, \\frac{\\partial h}{ \\partial y} + (M_{xy}^{B}(x,y,0) + T^0_{xy}) \\frac{\\partial h}{ \\partial x}\\; . $$\n",
    "\n",
    "Cerruti's solutions are as follows (assuming a point source loading in the $+x$ \n",
    "direction:\n",
    "\n",
    "$$ G_{xx}^{C_x} = \\frac{ F_{h,x} x }{2 \\pi r^3} \\left[ \\frac{ 3x^2}{r^2} \\right. - \\frac{\\mu}{(\\lambda + \\mu)(z+r)^2} \\left. (r^2 - y^2 - \\frac{2ry^2}{r+z}) \\right] $$\n",
    "\n",
    "$$ G_{yy}^{C_x} = \\frac{ F_{h,x} x }{2 \\pi r^3} \\left[ \\frac{ 3y^2}{r^2} \\right. - \\frac{\\mu}{(\\lambda + \\mu)(z+r)^2} \\left. (3r^2 - x^2 - \\frac{2rx^2}{r+z}) \\right] $$\n",
    "\n",
    "$$ G_{xy}^{C_x} = \\frac{ F_{h,x} x }{2 \\pi r^3} \\left[ \\frac{ 3x^2}{r^2} \\right. - \\frac{\\mu}{(\\lambda + \\mu)(z+r)^2} \\left. \\cdot (r^2 - x^2 - \\frac{2rx^2}{r+z}) \\right] $$\n",
    "\n",
    "$$ G^{C_x}_{zz} = \\frac{ 3 F_{h,x} x z^2 }{2 \\pi r^5} $$\n",
    "\n",
    "$$ G^{C_x}_{xz} = \\frac{ 3 F_{h,x} z x^2 }{2 \\pi r^5} $$\n",
    "\n",
    "$$ G^{C_x}_{yz} = \\frac{ 3 F_{h,x} x y z }{2 \\pi r^5} $$\n",
    "\n",
    "These equations are then re-used, with $x$ and $y$ switched, to calculate the\n",
    "stresses from loads in the $y$ direction.\n",
    "\n",
    "[intro]: ../halfspace-load-intro/\n",
    "[point_load_image]: /images/point_load_diagram.png\n",
    "[dem_prep]: ../halfspace-dem-prep/\n",
    "[bouss]: http://en.wikipedia.org/wiki/Joseph_Valentin_Boussinesq\n",
    "[gf]: http://en.wikipedia.org/wiki/Green's_function\n",
    "[sp]: http://en.wikipedia.org/wiki/Superposition_principle\n",
    "[convolve]: http://en.wikipedia.org/wiki/Convolution\n",
    "[array_load_image]: /images/topo_point_load.png\n",
    "[lz92]: http://engr.uconn.edu/~lanbo/1992JGR.pdf\n",
    "[hj]: http://en.wikipedia.org/wiki/Harold_Jeffreys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the topographic stress field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we calculate the 3D topographic stresses in the region below the DEM.  We first calculate the vertical (Boussinesq) stresses, then the horizontal/ slope (Cerruti) correction, then add them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import halfspace.load as hs\n",
    "import halfspace.sandbox as hbx\n",
    "import time\n",
    "import h5py\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set some path and file names.\n",
    "\n",
    "We use compressed HDF5 files for storage, using the `h5py` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_dir = '../stress_arrays/'\n",
    "b_stress_file = stress_dir + 'baloch_bouss_stress.h5'\n",
    "c_stress_file = stress_dir + 'baloch_cerr_stress.h5'\n",
    "stress_file = stress_dir + 'baloch_topo_stress.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_file = '../test_data/dem/baloch_dem_utm41n_445m.npy'\n",
    "dem_metadata_file = '../test_data/dem/baloch_dem_metadata.json'\n",
    "\n",
    "d_meta = json.load(open(dem_metadata_file, 'r')) # DEM metadata dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the current implementation of `halfspace` (v 0.5), topography and gravity are negative, and depth is positive.  Future versions of halfspace may consider topography (above sea level) and gravity as positive; this will change the coordinate system from the current left-handed system (East, North, Down) to right-handed (East, North, Up). So check the version and release notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 2700  # density in kg m^-3\n",
    "g = 9.81    # gravitational force in m s^-2\n",
    "Fv = - rho * g\n",
    "study_res = int(d_meta['x_res_m']) # resolution for topography, filters, etc.\n",
    "z_res = 1000\n",
    "b_conv_mode = 'valid'\n",
    "c_conv_mode = 'same'\n",
    "\n",
    "z_min = int(d_meta['x_res_m'])\n",
    "z_max = z_min + 26000\n",
    "z_len = int( (z_max - z_min) / z_res + 1)\n",
    "z_vec = np.linspace(z_min, z_max, num=z_len)\n",
    "\n",
    "kernel_rad = 1.5e5\n",
    "kernel_len = int( kernel_rad * 2 / study_res +1 )\n",
    "kernel_shape = np.array( [kernel_len, kernel_len] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load topography (DEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loading')\n",
    "t0 = time.time()\n",
    "topo = np.load(dem_file)\n",
    "topo *= -1 # new solutions use negative topo\n",
    "topo_shape = topo.shape\n",
    "t1 = time.time()\n",
    "print('done in', t1 - t0, 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: pad DEM for FFT convolution\n",
    "\n",
    "Depending on the relative sizes of the DEM, fault, and kernel width, it may be desirable to pad the DEM prior to convolution.  In our case, the fault is sufficiently far from the borders of the DEM that no padding should be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_dem = False\n",
    "\n",
    "if pad_dem:\n",
    "    topo_prepad_shape = topo.shape\n",
    "    topo = np.pad(topo, kernel_len//2, mode='constant', constant_values=[0.])\n",
    "    topo_shape = topo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now for the automated part.\n",
    "\n",
    "All the configuration should be done above this point,\n",
    "and below this, the cells can simply be executed.\n",
    "\n",
    "Therefore, when using this guide as a template to do this work for\n",
    "different locations, you don't need to modify anything below here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do some configuration and make empty topo stress arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_out_x, b_out_y = hbx.size_output(kernel_shape, topo_shape, mode=b_conv_mode)\n",
    "b_out_size = np.array( (b_out_x, b_out_y, z_len ) )\n",
    "b_stress = np.empty( (b_out_size) )\n",
    "\n",
    "b_db = h5py.File(b_stress_file)\n",
    "b_dict = {}\n",
    "comp_list = ['zz', 'xy', 'xz', 'yz', 'xx', 'yy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boussinesq convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = time.time()\n",
    "for comp in comp_list:\n",
    "    print('working on {} stresses'.format(comp) )\n",
    "    b_dict[comp] = b_stress.copy()\n",
    "\n",
    "    for i, z in enumerate(z_vec):\n",
    "       b_dict[comp][:,:,i] = hs.do_b_convo(component=comp,  z=z, Fv=Fv,\n",
    "                                           load=topo, load_mode='topo',\n",
    "                                           conv_mode=b_conv_mode, \n",
    "                                           kernel_radius=kernel_rad,\n",
    "                                           kernel_res=study_res)\n",
    "\n",
    "    b_dict[comp] *= 1e-6  # scale results to MPa\n",
    "    \n",
    "    b_db.create_dataset('b_{}_MPa'.format(comp), data = b_dict[comp],\n",
    "                     chunks = True, compression = 'gzip')\n",
    "\n",
    "    del b_dict[comp]\n",
    "\n",
    "print('done with Boussinesq calcs in', (time.time() - t2) / 60., 'm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cerruti convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate horizontal loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boussinesq stresses for xx, xy and yy are used in the loading function\n",
    "b_xx_top = b_db['b_xx_MPa'][:,:,0] * 1e6\n",
    "b_xy_top = b_db['b_xy_MPa'][:,:,0] * 1e6\n",
    "b_yy_top = b_db['b_yy_MPa'][:,:,0] * 1e6\n",
    "b_shape = b_xx_top.shape\n",
    "\n",
    "topo = hs._centered(topo, b_shape)\n",
    "\n",
    "topo_dy, topo_dx = np.gradient(topo, study_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make horizontal loading functions\n",
    "Fht_x = topo * Fv * topo_dx\n",
    "Fhb_x = b_xx_top * topo_dx + b_xy_top * topo_dy \n",
    "\n",
    "Fht_y = topo * Fv * topo_dy\n",
    "Fhb_y = b_yy_top * topo_dy + b_xy_top * topo_dx\n",
    "\n",
    "Fh_x = Fht_x + Fhb_x\n",
    "Fh_y = Fht_y + Fhb_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Cerruti output arrays\n",
    "c_x = np.zeros([topo.shape[0], topo.shape[1], z_len])\n",
    "c_y = c_x.copy()\n",
    "c_db = h5py.File(c_stress_file)\n",
    "t_db = h5py.File(stress_file)\n",
    "\n",
    "del topo # save some ram\n",
    "\n",
    "cerr_x = {}\n",
    "cerr_y = {}\n",
    "total_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Cerruti convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = time.time()\n",
    "for comp in comp_list:\n",
    "    print('working on {} stresses'.format(comp))\n",
    "\n",
    "    cerr_x[comp] = c_x.copy()\n",
    "    cerr_y[comp] = c_y.copy()\n",
    "\n",
    "    for i, z in enumerate(z_vec):\n",
    "        cerr_x[comp][:,:,i] = hs.do_c_convo(component=comp, f_dir='x',z=z,\n",
    "                                            load=Fh_x, kernel_res=study_res,\n",
    "                                            kernel_radius=kernel_rad,\n",
    "                                            conv_mode=c_conv_mode) * 1e-6\n",
    "\n",
    "        cerr_y[comp][:,:,i] = hs.do_c_convo(component=comp, f_dir='y', z=z,\n",
    "                                            load=Fh_y, kernel_res=study_res,\n",
    "                                            kernel_radius=kernel_rad,\n",
    "                                            conv_mode=c_conv_mode) * 1e-6\n",
    "\n",
    "    print('saving {} data'.format(comp))\n",
    "    c_db.create_dataset('c_{}_x_MPa'.format(comp), \n",
    "                      data = cerr_x[comp], chunks=True, compression = 'gzip')\n",
    "\n",
    "    c_db.create_dataset('c_{}_y_MPa'.format(comp), \n",
    "                      data = cerr_y[comp], chunks=True, compression = 'gzip')\n",
    "\n",
    "    print('adding all results together')\n",
    "    total_dict[comp] = (b_db['b_{}_MPa'.format(comp)][:,:,:] +  cerr_x[comp] \n",
    "                        + cerr_y[comp] )\n",
    "\n",
    "    t_db.create_dataset('{}_MPa'.format(comp), data=total_dict[comp],\n",
    "                        chunks = True, compression = 'gzip')\n",
    "\n",
    "    del total_dict[comp]\n",
    "    del cerr_x[comp]\n",
    "    del cerr_y[comp]\n",
    "\n",
    "print('done with topo corrections in', (time.time() - t3) / 60., 'm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_db.close()\n",
    "c_db.close()\n",
    "t_db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done in', (time.time() - t0) / 60., 'm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files `baloch_cerr_stress.h5` and `baloch_bouss_stress.h5` take up a lot of room, and may be deleted, unless inspection of them is desired (and if so, it may be simpler to just generate them again, rather than keep ~3-8 GB (depending on padding) of somewhat useless data on hand)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
